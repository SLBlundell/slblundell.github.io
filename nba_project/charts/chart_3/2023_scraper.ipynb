{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_scrape():\n",
    "    \n",
    "    teams = [\"Boston Celtics\", \"Brooklyn Nets\", \"New York Knicks\", \"Philadelphia 76ers\", \"Toronto Raptors\", \"Chicago Bulls\",\n",
    "    \"Cleveland Cavaliers\", \"Detroit Pistons\", \"Indiana Pacers\", \"Milwaukee Bucks\", \"Atlanta Hawks\", \"Charlotte Hornets\",\n",
    "    \"Miami Heat\", \"Orlando Magic\", \"Washington Wizards\", \"Denver Nuggets\", \"Minnesota Timberwolves\", \"Oklahoma City Thunder\",\n",
    "    \"Portland Trail Blazers\", \"Utah Jazz\", \"Golden State Warriors\", \"Los Angeles Clippers\", \"Los Angeles Lakers\", \"Phoenix Suns\",\n",
    "    \"Sacramento Kings\", \"Dallas Mavericks\", \"Houston Rockets\", \"Memphis Grizzlies\", \"New Orleans Pelicans\", \"San Antonio Spurs\"]\n",
    "\n",
    "    url_team = 'https://www.basketball-reference.com/leagues/NBA_2023.html'\n",
    "    url_team_payroll = 'https://hoopshype.com/salaries/'\n",
    "\n",
    "    # TEAM STATS\n",
    "\n",
    "    team_stats = requests.get(url_team)\n",
    "\n",
    "    # create BeautifulSoup object\n",
    "    soup = BeautifulSoup(team_stats.content, 'html.parser')\n",
    "\n",
    "    # locate correct table\n",
    "    table = soup.find(lambda tag: tag.name=='table' and tag.has_attr('id') and tag['id']==\"per_game-team\") \n",
    "    rows = table.findAll(lambda tag: tag.name=='tr')\n",
    "\n",
    "    # create DataFrame\n",
    "    df = pd.read_html(str(table))[0]\n",
    "\n",
    "    # clean DataFrame\n",
    "    df = df.drop(index=30)\n",
    "    df.insert(2, \"Year\", 2023, True)\n",
    "    df = df.drop(columns=[\"G\",\"Rk\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # add advanced stats to DataFrame\n",
    "    table = soup.find(lambda tag: tag.name=='table' and tag.has_attr('id') and tag['id']==\"advanced-team\") \n",
    "    rows = table.findAll(lambda tag: tag.name=='tr')\n",
    "\n",
    "    df_adv = pd.read_html(str(table))[0]\n",
    "\n",
    "    df_adv.columns = df_adv.columns.droplevel()\n",
    "    df_adv = df_adv.drop(index=30)\n",
    "    df_adv['Team'] = df_adv['Team'].str.replace('*', '')\n",
    "    df_adv = df_adv.drop(columns=[\"Rk\", \"L\", \"PW\", \"PL\", \"Unnamed: 17_level_1\", \"Unnamed: 22_level_1\", \"Unnamed: 27_level_1\", \"Arena\"])\n",
    "    df_adv = df_adv.reset_index(drop=True)\n",
    "\n",
    "    # merge per game and advanced stats\n",
    "    df_team = pd.merge(df, df_adv, on='Team')\n",
    "\n",
    "    # further cleaning\n",
    "    df_team.columns.values[40] = \"Op_eFG%\"\n",
    "    df_team.insert(46, \"Playoff_W\", 0)\n",
    "\n",
    "    # TEAM SALARIES\n",
    "\n",
    "    payrolls = requests.get(url_team_payroll)\n",
    "    soup = BeautifulSoup(payrolls.content, 'html.parser')\n",
    "\n",
    "    table = soup.find(\"table\", class_=\"hh-salaries-ranking-table hh-salaries-table-sortable responsive\")\n",
    "    rows = table.findAll(lambda tag: tag.name=='tr')\n",
    "\n",
    "    df_payroll = pd.read_html(str(table))[0]\n",
    "\n",
    "    # cleaning\n",
    "    df_payroll = df_payroll.iloc[:, [1,2]]\n",
    "    df_payroll['2022/23'] = df_payroll['2022/23'].str.replace('[$,]', '').astype(int)\n",
    "    df_payroll = df_payroll.rename(columns={'2022/23': 'Payroll'})\n",
    "\n",
    "    # As salary data uses shortened team names, these names must be replaced with full team names in order to ensure\n",
    "    # proper merging of salary and team data. This is achieved by comparing similarity of salary data team name\n",
    "    # strings with full team name strings stored in a list\n",
    "    team_replace = {row: team for row in df_payroll['Team'].to_list() for team in teams if similar(row, team)>=0.53}\n",
    "\n",
    "    for index, team in team_replace.items():\n",
    "        df_payroll.loc[df_payroll['Team'] == index, 'Team'] = team\n",
    "\n",
    "    # merge per game and advanced stats\n",
    "    df_team = pd.merge(df_team, df_payroll, on='Team')\n",
    "    df_team = df_team.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    # write data to csv\n",
    "    df_team.to_csv('C:/Users/whisk/OneDrive/Documents/Bristol/Economics/Year 4/Data Science/slblundell.github.io/nba_project/data/team_per_game_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_scrape():\n",
    "\n",
    "    url_player = 'https://www.basketball-reference.com/leagues/NBA_2023_per_game.html'\n",
    "    url_player_adv = 'https://www.basketball-reference.com/leagues/NBA_2023_advanced.html'\n",
    "    url_player_salary = 'https://hoopshype.com/salaries/players/'\n",
    "\n",
    "    # PLAYER STATS\n",
    "\n",
    "    per_game = requests.get(url_player)\n",
    "    adv = requests.get(url_player_adv)\n",
    "\n",
    "    # create BeautifulSoup object\n",
    "    soup = BeautifulSoup(per_game.content, 'html.parser')\n",
    "\n",
    "    # locate correct table\n",
    "    table = soup.find(\"table\", class_=\"sortable stats_table\")\n",
    "    rows = table.findAll(lambda tag: tag.name=='tr')\n",
    "\n",
    "    # create DataFrame\n",
    "    df = pd.read_html(str(table))[0]\n",
    "\n",
    "    # clean DataFrame\n",
    "    df = df.drop(index=30)\n",
    "    df = df.drop(columns=[\"G\",\"Rk\", \"GS\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # create BeautifulSoup object\n",
    "    soup = BeautifulSoup(adv.content, 'html.parser')\n",
    "\n",
    "    # add advanced stats to DataFrame\n",
    "    table = soup.find(\"table\", class_=\"sortable stats_table\") \n",
    "    rows = table.findAll(lambda tag: tag.name=='tr')\n",
    "    df_adv = pd.read_html(str(table))[0]\n",
    "    df_adv = df_adv.drop(columns=[\"Rk\", \"G\", \"Tm\", \"MP\", \"Pos\", \"Age\", \"Unnamed: 19\", \"Unnamed: 24\"])\n",
    "    df_adv = df_adv.reset_index(drop=True)\n",
    "\n",
    "    df_player = pd.merge(df, df_adv, on='Player')\n",
    "\n",
    "    # drop junk rows\n",
    "    df_player = df_player.drop(df_player[df_player.Player == \"Player\"].index)\n",
    "\n",
    "    # reformat accented Player characters\n",
    "    df_player[\"Player\"] = df_player[\"Player\"].apply(lambda x: unidecode(x))\n",
    "    df_player['Player'] = df_player['Player'].str.replace('.', '')\n",
    "\n",
    "    # drop duplicate players (players traded mid-season. NOTE: this approach should be altered if significant \n",
    "    # players are traded as the season progresses)\n",
    "    df_player = df_player.drop_duplicates(subset=\"Player\", keep='first').reset_index(drop=True)\n",
    "\n",
    "    # PLAYER SALARIES\n",
    "\n",
    "    salary = requests.get(url_player_salary)\n",
    "\n",
    "    #create BeautifulSoup object\n",
    "    soup = BeautifulSoup(salary.content, 'html.parser')\n",
    "    print(soup.table)\n",
    "\n",
    "    #locate correct table\n",
    "    table = soup.find(\"table\", class_=\"hh-salaries-ranking-table hh-salaries-table-sortable responsive\")\n",
    "    rows = table.findAll(lambda tag: tag.name=='tr')\n",
    "\n",
    "    #create DataFrame\n",
    "    df_salary = pd.read_html(str(table))[0]\n",
    "\n",
    "    # drop junk column\n",
    "    df_salary = df_salary.drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "    # convert salaries to int\n",
    "    for column in df_salary.columns:\n",
    "        if column != \"Player\":\n",
    "            df_salary[column] = df_salary[column].str.replace('[$,]', '').astype(int)\n",
    "\n",
    "    # correct player names\n",
    "    df_salary = df_salary.replace({'Player': {'Sviatoslav Mykhailiuk': 'Svi Mykhailiuk', \n",
    "    'Scottie Pippen Jr': 'Scotty Pippen Jr', 'Josh Primo': 'Joshua Primo', 'Dennis Schroeder': 'Dennis Schroder', \n",
    "    'Ishmael Smith': 'Ish Smith', 'Santiago Aldama': 'Santi Aldama', 'BJ Boston': 'Brandon Boston Jr', \n",
    "    'Nicolas Claxton': 'Nic Claxton', \"Devonte Graham\": \"Devonte' Graham\", 'Juan Hernangomez': 'Juancho Hernangomez',\n",
    "    'Herb Jones': 'Herbert Jones', 'KJ Martin': 'Kenyon Martin Jr', 'Patrick Mills': 'Patty Mills', \n",
    "    'Ishmail Wainright': 'Ish Wainright'}})\n",
    "\n",
    "    # merge player dataframes\n",
    "    df_player_salary = pd.merge(df_player, df_salary, on='Player')\n",
    "    df_player_salary\n",
    "\n",
    "    # checking missing rows within between player and salary datasets\n",
    "    df_player_player_list = df_player[\"Player\"].tolist()\n",
    "    df_salary_player_list = df_salary[\"Player\"].tolist()\n",
    "\n",
    "    player_diff_1 = []\n",
    "    for player in df_player_player_list:\n",
    "        if player not in df_salary_player_list:\n",
    "            player_diff_1.append(player)\n",
    "\n",
    "    player_diff_2 = []\n",
    "    for player in df_salary_player_list:\n",
    "        if player not in df_player_player_list:\n",
    "            player_diff_2.append(player)\n",
    "\n",
    "    # correcting for differing naming conventions between datasets\n",
    "\n",
    "    for player in player_diff_2:\n",
    "        if f\"{player} Jr\" in player_diff_1:\n",
    "            df_salary['Player'] = df_salary['Player'].replace([player], f\"{player} Jr\")\n",
    "        if f\"{player} Sr\" in player_diff_1:\n",
    "            df_salary['Player'] = df_salary['Player'].replace([player], f\"{player} Sr\")\n",
    "        if f\"{player} III\" in player_diff_1:\n",
    "            df_salary['Player'] = df_salary['Player'].replace([player], f\"{player} III\")\n",
    "        if f\"{player} IV\" in player_diff_1:\n",
    "            df_salary['Player'] = df_salary['Player'].replace([player], f\"{player} IV\")\n",
    "\n",
    "    # merge corrected player dataframes \n",
    "    df_player_salary = pd.merge(df_player, df_salary, on='Player')\n",
    "\n",
    "    df_player_salary = df_player_salary.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    # write data to csv\n",
    "    df_player_salary.to_csv('C:/Users/whisk/OneDrive/Documents/Bristol/Economics/Year 4/Data Science/slblundell.github.io/nba_project/data/player_per_game_salary_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    team_scrape()\n",
    "    player_scrape()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bcf767d74aa0613621d814dbc311c100d7c513475831bdee7c609a7f5e52ccf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
